wandb: Currently logged in as: ligengchengucd (BDIC-DMML-2024). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /data0/user/gsli/Classifiers-enhanced-by-pre-training/wandb/run-20240413_201822-jv1t0wmh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crimson-energy-29
wandb: ‚≠êÔ∏è View project at https://wandb.ai/BDIC-DMML-2024/clip-linear-probe-classification
wandb: üöÄ View run at https://wandb.ai/BDIC-DMML-2024/clip-linear-probe-classification/runs/jv1t0wmh
Files already downloaded and verified
Files already downloaded and verified
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [04:10<13:52:13, 250.92s/it]  1%|          | 2/200 [08:16<13:37:41, 247.79s/it]  2%|‚ñè         | 3/200 [12:29<13:41:50, 250.31s/it]  2%|‚ñè         | 4/200 [16:41<13:39:04, 250.74s/it]  2%|‚ñé         | 5/200 [20:50<13:33:24, 250.28s/it]  3%|‚ñé         | 6/200 [25:03<13:32:16, 251.22s/it]  4%|‚ñé         | 7/200 [29:00<13:13:02, 246.54s/it]  4%|‚ñç         | 8/200 [33:12<13:14:03, 248.14s/it]  4%|‚ñç         | 9/200 [37:12<13:02:20, 245.76s/it]  5%|‚ñå         | 10/200 [41:27<13:07:29, 248.68s/it]  6%|‚ñå         | 11/200 [45:39<13:06:12, 249.59s/it]  6%|‚ñå         | 12/200 [49:53<13:06:17, 250.94s/it]  6%|‚ñã         | 13/200 [54:07<13:04:37, 251.75s/it]  7%|‚ñã         | 14/200 [58:21<13:02:41, 252.48s/it]  8%|‚ñä         | 15/200 [1:02:32<12:56:44, 251.92s/it]  8%|‚ñä         | 16/200 [1:06:45<12:54:03, 252.41s/it]  8%|‚ñä         | 17/200 [1:10:54<12:46:26, 251.29s/it]  9%|‚ñâ         | 18/200 [1:14:50<12:28:42, 246.83s/it] 10%|‚ñâ         | 19/200 [1:18:49<12:17:24, 244.44s/it] 10%|‚ñà         | 20/200 [1:23:01<12:20:10, 246.72s/it] 10%|‚ñà         | 21/200 [1:27:14<12:21:24, 248.52s/it] 11%|‚ñà         | 22/200 [1:31:26<12:20:51, 249.73s/it] 12%|‚ñà‚ñè        | 23/200 [1:35:40<12:19:59, 250.84s/it] 12%|‚ñà‚ñè        | 24/200 [1:39:52<12:16:35, 251.11s/it] 12%|‚ñà‚ñé        | 25/200 [1:44:04<12:13:49, 251.60s/it] 13%|‚ñà‚ñé        | 26/200 [1:48:16<12:09:22, 251.51s/it] 14%|‚ñà‚ñé        | 27/200 [1:52:29<12:06:58, 252.13s/it] 14%|‚ñà‚ñç        | 28/200 [1:56:30<11:53:18, 248.83s/it] 14%|‚ñà‚ñç        | 29/200 [2:00:33<11:43:53, 246.98s/it] 15%|‚ñà‚ñå        | 30/200 [2:04:19<11:21:34, 240.56s/it] 16%|‚ñà‚ñå        | 31/200 [2:08:24<11:21:52, 242.08s/it] 16%|‚ñà‚ñå        | 32/200 [2:12:29<11:20:12, 242.93s/it] 16%|‚ñà‚ñã        | 33/200 [2:16:32<11:15:55, 242.85s/it] 17%|‚ñà‚ñã        | 34/200 [2:20:36<11:12:49, 243.19s/it] 18%|‚ñà‚ñä        | 35/200 [2:24:35<11:05:41, 242.07s/it] 18%|‚ñà‚ñä        | 36/200 [2:28:37<11:01:25, 241.99s/it] 18%|‚ñà‚ñä        | 37/200 [2:32:40<10:58:13, 242.29s/it] 19%|‚ñà‚ñâ        | 38/200 [2:36:42<10:53:37, 242.08s/it] 20%|‚ñà‚ñâ        | 39/200 [2:40:27<10:36:21, 237.15s/it] 20%|‚ñà‚ñà        | 40/200 [2:44:24<10:32:19, 237.12s/it] 20%|‚ñà‚ñà        | 41/200 [2:48:12<10:20:59, 234.33s/it] 21%|‚ñà‚ñà        | 42/200 [2:52:18<10:25:59, 237.72s/it] 22%|‚ñà‚ñà‚ñè       | 43/200 [2:56:17<10:23:29, 238.28s/it] 22%|‚ñà‚ñà‚ñè       | 44/200 [3:00:18<10:21:20, 238.98s/it] 22%|‚ñà‚ñà‚ñé       | 45/200 [3:04:21<10:20:39, 240.25s/it] 23%|‚ñà‚ñà‚ñé       | 46/200 [3:08:23<10:17:37, 240.64s/it] 24%|‚ñà‚ñà‚ñé       | 47/200 [3:12:23<10:13:39, 240.65s/it] 24%|‚ñà‚ñà‚ñç       | 48/200 [3:16:26<10:11:12, 241.26s/it] 24%|‚ñà‚ñà‚ñç       | 49/200 [3:20:27<10:07:03, 241.22s/it] 25%|‚ñà‚ñà‚ñå       | 50/200 [3:24:12<9:50:47, 236.31s/it]  26%|‚ñà‚ñà‚ñå       | 51/200 [3:28:13<9:49:57, 237.56s/it] 26%|‚ñà‚ñà‚ñå       | 52/200 [3:32:04<9:41:14, 235.64s/it] 26%|‚ñà‚ñà‚ñã       | 53/200 [3:36:03<9:39:58, 236.73s/it] 27%|‚ñà‚ñà‚ñã       | 54/200 [3:40:05<9:40:06, 238.40s/it] 28%|‚ñà‚ñà‚ñä       | 55/200 [3:44:11<9:41:18, 240.54s/it] 28%|‚ñà‚ñà‚ñä       | 56/200 [3:48:12<9:37:26, 240.60s/it] 28%|‚ñà‚ñà‚ñä       | 57/200 [3:52:11<9:32:28, 240.20s/it] 29%|‚ñà‚ñà‚ñâ       | 58/200 [3:56:11<9:28:31, 240.22s/it] 30%|‚ñà‚ñà‚ñâ       | 59/200 [4:00:13<9:26:01, 240.86s/it] 30%|‚ñà‚ñà‚ñà       | 60/200 [4:04:17<9:24:10, 241.79s/it] 30%|‚ñà‚ñà‚ñà       | 61/200 [4:08:05<9:10:30, 237.63s/it] 31%|‚ñà‚ñà‚ñà       | 62/200 [4:12:00<9:04:50, 236.89s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [4:15:54<8:58:48, 235.97s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [4:19:58<9:00:26, 238.43s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [4:24:06<9:02:23, 241.06s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [4:28:14<9:02:58, 243.12s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [4:32:23<9:03:17, 245.09s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [4:36:30<9:00:16, 245.58s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [4:40:36<8:56:19, 245.65s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [4:44:35<8:48:08, 243.76s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [4:48:34<8:41:13, 242.43s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [4:52:25<8:29:25, 238.79s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [4:56:13<8:18:41, 235.60s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [5:00:13<8:17:52, 237.08s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [5:04:17<8:18:13, 239.15s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [5:08:28<8:21:01, 242.43s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [5:12:42<8:24:05, 245.90s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [5:16:56<8:25:20, 248.53s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [5:21:10<8:24:26, 250.14s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [5:25:24<8:22:41, 251.35s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [5:29:37<8:19:28, 251.83s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [5:33:33<8:06:00, 247.12s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [5:37:38<8:00:39, 246.49s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [5:41:37<7:52:02, 244.16s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [5:45:53<7:54:35, 247.61s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [5:50:04<7:52:25, 248.64s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [5:54:15<7:49:58, 249.54s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [5:58:29<7:48:16, 250.86s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [6:02:40<7:43:58, 250.80s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [6:06:50<7:39:16, 250.51s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [6:11:06<7:38:03, 252.14s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [6:15:06<7:27:30, 248.62s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [6:19:15<7:23:42, 248.81s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [6:23:11<7:12:29, 244.81s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [6:27:22<7:11:31, 246.58s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [6:31:31<7:08:53, 247.44s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [6:35:46<7:08:30, 249.62s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [6:40:02<7:07:31, 251.48s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [6:44:17<7:05:18, 252.66s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [6:48:28<7:00:17, 252.17s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [6:52:47<6:59:19, 254.13s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [6:56:55<6:52:09, 252.34s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [7:00:54<6:41:41, 248.47s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [7:04:53<6:32:54, 245.57s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [7:09:04<6:31:31, 247.28s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [7:13:20<6:31:12, 249.71s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [7:17:33<6:28:33, 250.69s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [7:21:47<6:25:49, 251.63s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [7:26:00<6:22:13, 252.02s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [7:30:15<6:19:36, 253.08s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [7:34:28<6:15:14, 252.97s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [7:38:43<6:12:01, 253.65s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [7:42:36<5:58:40, 247.36s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [7:46:32<5:49:44, 244.00s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [7:50:44<5:49:15, 246.54s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [7:55:01<5:49:15, 249.48s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [7:59:13<5:46:11, 250.26s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [8:03:21<5:41:01, 249.53s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [8:07:29<5:36:28, 249.24s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [8:11:42<5:33:45, 250.32s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [8:15:56<5:31:02, 251.43s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [8:20:09<5:27:26, 251.88s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [8:24:04<5:16:55, 246.96s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [8:28:10<5:12:22, 246.62s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [8:32:12<5:06:16, 245.02s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [8:36:24<5:04:48, 247.15s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [8:40:37<5:02:52, 248.94s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [8:44:48<4:59:32, 249.62s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [8:49:00<4:56:11, 250.31s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [8:53:15<4:53:48, 251.84s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [8:57:28<4:49:44, 251.94s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [9:01:27<4:41:13, 248.15s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [9:05:16<4:30:40, 242.39s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [9:08:56<4:19:18, 235.74s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [9:12:37<4:10:35, 231.32s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [9:16:27<4:06:17, 230.90s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [9:20:18<4:02:33, 231.01s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [9:24:12<3:59:41, 231.96s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [9:28:04<3:55:53, 232.02s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [9:31:58<3:52:19, 232.32s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [9:35:57<3:50:25, 234.32s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [9:39:55<3:47:48, 235.67s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [9:43:54<3:44:39, 236.48s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [9:47:56<3:42:15, 238.14s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [9:51:46<3:36:07, 235.78s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [9:55:42<3:32:20, 235.93s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [9:59:38<3:28:20, 235.85s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [10:03:43<3:26:48, 238.62s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [10:07:47<3:24:17, 240.35s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [10:11:44<3:19:24, 239.29s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [10:15:35<3:13:26, 236.87s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [10:19:25<3:07:51, 234.82s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [10:23:15<3:02:48, 233.37s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [10:27:05<2:58:02, 232.22s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [10:30:54<2:53:20, 231.13s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [10:34:34<2:47:06, 227.88s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [10:38:22<2:43:28, 228.10s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [10:41:57<2:36:48, 224.00s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [10:45:42<2:33:20, 224.41s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [10:49:28<2:29:47, 224.68s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [10:53:19<2:27:20, 226.67s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [10:57:08<2:24:02, 227.43s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [11:00:58<2:20:41, 228.14s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [11:04:49<2:17:21, 228.93s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [11:08:38<2:13:36, 229.05s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [11:12:25<2:09:27, 228.46s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [11:16:14<2:05:46, 228.70s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [11:19:50<1:59:50, 224.70s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [11:23:40<1:56:53, 226.23s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [11:27:18<1:52:00, 224.02s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [11:31:09<1:49:13, 226.00s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [11:35:00<1:46:08, 227.46s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [11:38:51<1:42:53, 228.65s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [11:42:40<1:39:04, 228.64s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [11:46:28<1:35:12, 228.49s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [11:50:17<1:31:29, 228.71s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [11:54:04<1:27:28, 228.21s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [11:57:53<1:23:46, 228.46s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [12:01:43<1:20:05, 228.82s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [12:05:20<1:15:07, 225.37s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [12:09:03<1:11:08, 224.65s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [12:12:47<1:07:20, 224.45s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [12:16:36<1:03:58, 225.81s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [12:20:26<1:00:29, 226.86s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [12:24:14<56:47, 227.19s/it]   93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [12:28:00<52:59, 227.12s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [12:31:49<49:19, 227.62s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [12:35:36<45:28, 227.40s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [12:39:24<41:42, 227.50s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [12:43:15<38:06, 228.64s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [12:46:59<34:04, 227.18s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [12:50:38<29:57, 224.67s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [12:54:16<25:59, 222.73s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [12:58:02<22:21, 223.66s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [13:01:49<18:43, 224.67s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [13:05:38<15:03, 225.93s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [13:09:24<11:18, 226.03s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [13:13:12<07:33, 226.63s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [13:17:00<03:47, 227.03s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [13:20:48<00:00, 227.35s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [13:20:48<00:00, 240.24s/it]
Epoch: 0, Average Loss: 4.141560483664369, Trn Accuracy: 6.94%, lr: 5e-05
Average Val Loss: 3.883603373660317, Val_accuracy: 10.77
Epoch: 1, Average Loss: 3.7712618078286657, Trn Accuracy: 12.47%, lr: 4.998766400914329e-05
Average Val Loss: 3.712223400043536, Val_accuracy: 12.88
Epoch: 2, Average Loss: 3.5642591878628958, Trn Accuracy: 15.82%, lr: 4.995066821070679e-05
Average Val Loss: 3.507721674593189, Val_accuracy: 16.91
Epoch: 3, Average Loss: 3.3935832916357267, Trn Accuracy: 19.07%, lr: 4.9889049115077005e-05
Average Val Loss: 3.357201500783993, Val_accuracy: 19.53
Epoch: 4, Average Loss: 3.265114820803316, Trn Accuracy: 21.11%, lr: 4.9802867532861956e-05
Average Val Loss: 3.267792626272274, Val_accuracy: 21.29
Epoch: 5, Average Loss: 3.1584899341717314, Trn Accuracy: 23.19%, lr: 4.969220851487845e-05
Average Val Loss: 3.177257857745207, Val_accuracy: 22.97
Epoch: 6, Average Loss: 3.0851276949190867, Trn Accuracy: 24.86%, lr: 4.9557181268217227e-05
Average Val Loss: 3.184663748439354, Val_accuracy: 22.41
Epoch: 7, Average Loss: 3.023516287818884, Trn Accuracy: 26.24%, lr: 4.939791904846869e-05
Average Val Loss: 3.1441060621527175, Val_accuracy: 22.76
Epoch: 8, Average Loss: 2.976342416799868, Trn Accuracy: 27.20%, lr: 4.921457902821578e-05
Average Val Loss: 3.0874726138537443, Val_accuracy: 24.09
Epoch: 9, Average Loss: 2.9221648057809655, Trn Accuracy: 28.25%, lr: 4.9007342141923585e-05
Average Val Loss: 3.0427036466477793, Val_accuracy: 25.38
Epoch: 10, Average Loss: 2.881040905992063, Trn Accuracy: 28.86%, lr: 4.877641290737885e-05
Average Val Loss: 3.0209135979036743, Val_accuracy: 25.33
Epoch: 11, Average Loss: 2.8491042132575672, Trn Accuracy: 29.48%, lr: 4.852201922385565e-05
Average Val Loss: 2.9800799888900564, Val_accuracy: 25.97
Epoch: 12, Average Loss: 2.820851977259968, Trn Accuracy: 30.32%, lr: 4.82444121472063e-05
Average Val Loss: 2.979980019074452, Val_accuracy: 26.04
Epoch: 13, Average Loss: 2.7870424837350085, Trn Accuracy: 30.67%, lr: 4.794386564209954e-05
Average Val Loss: 2.9593761118152475, Val_accuracy: 26.67
Epoch: 14, Average Loss: 2.7682838135253127, Trn Accuracy: 31.02%, lr: 4.76206763116505e-05
Average Val Loss: 2.94389205944689, Val_accuracy: 26.88
Epoch: 15, Average Loss: 2.7381396369812205, Trn Accuracy: 31.80%, lr: 4.727516310470921e-05
Average Val Loss: 2.917103314701515, Val_accuracy: 27.03
Epoch: 16, Average Loss: 2.7214941102475785, Trn Accuracy: 31.67%, lr: 4.6907667001096604e-05
Average Val Loss: 2.9169946169551415, Val_accuracy: 27.92
Epoch: 17, Average Loss: 2.693844230030291, Trn Accuracy: 32.47%, lr: 4.651855067509861e-05
Average Val Loss: 2.889965811862221, Val_accuracy: 27.4
Epoch: 18, Average Loss: 2.678314144999836, Trn Accuracy: 32.80%, lr: 4.61081981375504e-05
Average Val Loss: 2.924398072158234, Val_accuracy: 27.12
Epoch: 19, Average Loss: 2.660668714358784, Trn Accuracy: 33.22%, lr: 4.567701435686407e-05
Average Val Loss: 2.88846360279035, Val_accuracy: 27.41
Epoch: 20, Average Loss: 2.6460621189385556, Trn Accuracy: 33.34%, lr: 4.522542485937371e-05
Average Val Loss: 2.871603371221808, Val_accuracy: 28.28
Epoch: 21, Average Loss: 2.6239643919582183, Trn Accuracy: 34.02%, lr: 4.475387530939228e-05
Average Val Loss: 2.862869368323797, Val_accuracy: 28.35
Epoch: 22, Average Loss: 2.6073560067259085, Trn Accuracy: 34.14%, lr: 4.426283106939476e-05
Average Val Loss: 2.8377111259895034, Val_accuracy: 29.18
Epoch: 23, Average Loss: 2.5940369592307095, Trn Accuracy: 34.55%, lr: 4.375277674076152e-05
Average Val Loss: 2.8368640368497826, Val_accuracy: 29.39
Epoch: 24, Average Loss: 2.5828362943265386, Trn Accuracy: 34.65%, lr: 4.3224215685535314e-05
Average Val Loss: 2.831392924996871, Val_accuracy: 28.45
Epoch: 25, Average Loss: 2.564792769404646, Trn Accuracy: 35.01%, lr: 4.267766952966371e-05
Average Val Loss: 2.85165422173995, Val_accuracy: 29.16
Epoch: 26, Average Loss: 2.540505837327756, Trn Accuracy: 35.51%, lr: 4.211367764821724e-05
Average Val Loss: 2.837936935545523, Val_accuracy: 29.03
Epoch: 27, Average Loss: 2.531847189028804, Trn Accuracy: 35.67%, lr: 4.1532796633091316e-05
Average Val Loss: 2.8425515301619906, Val_accuracy: 29.03
Epoch: 28, Average Loss: nan, Trn Accuracy: 26.90%, lr: 4.093559974371726e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 29, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.0322676341324435e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 30, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.969463130731186e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 31, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.9052084446303294e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 32, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.839566987447494e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 33, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.772603539375931e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 34, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.704384185254291e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 35, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.63497624934887e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 36, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.564448228912685e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 37, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.492869726586954e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 38, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.4203113817116984e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 39, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.346844800613232e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 40, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.272542485937372e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 41, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.197477765098077e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 42, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.12172471791214e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 43, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.0453581034913598e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 44, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.968453286464315e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 45, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.8910861626005803e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 46, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.8133330839107642e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 47, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.7352707832962885e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 48, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.6569762988232866e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 49, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.5785268976953237e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 50, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.5000000000000028e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 51, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.421473102304682e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 52, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.343023701176719e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 53, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.2647292167037164e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 54, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.1866669160892418e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 55, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.108913837399425e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 56, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.0315467135356907e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 57, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.9546418965086466e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 58, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.878275282087865e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 59, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.8025222349019294e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 60, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.7274575140626345e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 61, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.6531551993867737e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 62, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.579688618288308e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 63, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.5071302734130502e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 64, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.4355517710873202e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 65, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.365023750651135e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 66, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.2956158147457131e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 67, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.2273964606240733e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 68, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.1604330125525094e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 69, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.0947915553696749e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 70, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.030536869268819e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 71, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.677323658675599e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 72, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.06440025628277e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 73, Average Loss: nan, Trn Accuracy: 1.00%, lr: 8.46720336690872e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 74, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.886322351782794e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 75, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.322330470336325e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 76, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.775784314464728e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 77, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.24722325923852e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 78, Average Loss: nan, Trn Accuracy: 1.00%, lr: 5.737168930605281e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 79, Average Loss: nan, Trn Accuracy: 1.00%, lr: 5.246124690607749e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 80, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.774575140626324e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 81, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.322985643135964e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 82, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.891801862449635e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 83, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.4814493249014116e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 84, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.0923329989034154e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 85, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.7248368952908095e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 86, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.37932368834952e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 87, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.0561343579004804e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 88, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.7555878527937192e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 89, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.4779807761443662e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 90, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.2235870926211638e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 91, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.926578580764278e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 92, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.854209717842272e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 93, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.020809515313179e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 94, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.4281873178278274e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 95, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.0779148512155904e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 96, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.9713246713805623e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 97, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.1095088492300029e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 98, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.933178929321111e-08
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 99, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.233599085671002e-08
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 100, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 101, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.233599085671e-08
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 102, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.9331789293211026e-08
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 103, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.1095088492300009e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 104, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.971324671380531e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 105, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.0779148512155576e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 106, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.428187317827848e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 107, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.020809515313143e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 108, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.854209717842205e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 109, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.926578580764206e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 110, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.223587092621159e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 111, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.4779807761443636e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 112, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.7555878527937134e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 113, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.0561343579004686e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 114, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.3793236883495076e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 115, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.724836895290808e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 116, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.092332998903413e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 117, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.4814493249014082e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 118, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.89180186244962e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 119, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.3229856431359484e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 120, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.7745751406263055e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 121, Average Loss: nan, Trn Accuracy: 1.00%, lr: 5.246124690607742e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 122, Average Loss: nan, Trn Accuracy: 1.00%, lr: 5.737168930605269e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 123, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.247223259238507e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 124, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.775784314464706e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 125, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.3223304703363025e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 126, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.886322351782784e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 127, Average Loss: nan, Trn Accuracy: 1.00%, lr: 8.467203366908702e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 128, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.064400256282762e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 129, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.677323658675589e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 130, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.030536869268817e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 131, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.0947915553696728e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 132, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.1604330125525094e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 133, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.2273964606240725e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 134, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.2956158147457121e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 135, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.3650237506511328e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 136, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.4355517710873197e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 137, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.5071302734130494e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 138, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.5796886182883056e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 139, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.6531551993867717e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 140, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.727457514062631e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 141, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.8025222349019264e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 142, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.8782752820878645e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 143, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.9546418965086445e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 144, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.031546713535689e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 145, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.108913837399423e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 146, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.186666916089239e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 147, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.2647292167037154e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 148, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.343023701176717e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 149, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.4214731023046796e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 150, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.4999999999999998e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 151, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.57852689769532e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 152, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.6569762988232825e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 153, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.735270783296287e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 154, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.813333083910761e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 155, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.8910861626005772e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 156, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.9684532864643116e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 157, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.045358103491356e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 158, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.121724717912138e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 159, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.1974777650980735e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 160, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.2725424859373684e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 161, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.346844800613228e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 162, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.4203113817116936e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 163, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.49286972658695e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 164, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.56444822891268e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 165, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.634976249348865e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 166, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.70438418525429e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 167, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.7726035393759305e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 168, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.839566987447494e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 169, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.905208444630329e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 170, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.969463130731184e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 171, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.032267634132442e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 172, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.0935599743717254e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 173, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.153279663309131e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 174, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.211367764821722e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 175, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.267766952966369e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 176, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.322421568553531e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 177, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.375277674076151e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 178, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.4262831069394764e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 179, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.4753875309392286e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 180, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.5225424859373724e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 181, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.567701435686408e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 182, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.6108198137550413e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 183, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.6518550675098624e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 184, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.690766700109662e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 185, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.7275163104709234e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 186, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.7620676311650524e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 187, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.794386564209957e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 188, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.824441214720632e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 189, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.8522019223855676e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 190, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.877641290737888e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 191, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.900734214192361e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 192, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.921457902821582e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 193, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.939791904846872e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 194, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.955718126821726e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 195, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.9692208514878484e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 196, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.980286753286198e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 197, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.988904911507704e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 198, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.9950668210706834e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 199, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.998766400914333e-05
Average Val Loss: nan, Val_accuracy: 1.0
Accuracy on the 10000 test images: 1.0%
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.046 MB uploadedwandb: | 0.013 MB of 0.046 MB uploadedwandb: / 0.046 MB of 0.046 MB uploadedwandb: 
wandb: Run history:
wandb:     average_loss ‚ñà‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ                                  
wandb: average_val_loss ‚ñà‚ñÑ‚ñÇ‚ñÇ‚ñÅ‚ñÅ                                  
wandb:            epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:               lr ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:    test_accuracy ‚ñÅ
wandb:     trn_accuracy ‚ñÉ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:     val_accuracy ‚ñÑ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:     average_loss nan
wandb: average_val_loss nan
wandb:            epoch 199
wandb:               lr 5e-05
wandb:    test_accuracy 1.0
wandb:     trn_accuracy 1.0
wandb:     val_accuracy 1.0
wandb: 
wandb: üöÄ View run crimson-energy-29 at: https://wandb.ai/BDIC-DMML-2024/clip-linear-probe-classification/runs/jv1t0wmh
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/BDIC-DMML-2024/clip-linear-probe-classification
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240413_201822-jv1t0wmh/logs
