wandb: Currently logged in as: ligengchengucd (BDIC-DMML-2024). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /data0/user/gsli/Classifiers-enhanced-by-pre-training/wandb/run-20240413_202158-ot5iz4h7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-puddle-31
wandb: ‚≠êÔ∏è View project at https://wandb.ai/BDIC-DMML-2024/clip-linear-probe-classification
wandb: üöÄ View run at https://wandb.ai/BDIC-DMML-2024/clip-linear-probe-classification/runs/ot5iz4h7
Files already downloaded and verified
Files already downloaded and verified
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [03:33<11:47:09, 213.21s/it]  1%|          | 2/200 [07:02<11:36:23, 211.03s/it]  2%|‚ñè         | 3/200 [10:35<11:34:46, 211.61s/it]  2%|‚ñè         | 4/200 [14:01<11:24:43, 209.61s/it]  2%|‚ñé         | 5/200 [17:28<11:18:28, 208.76s/it]  3%|‚ñé         | 6/200 [20:55<11:12:42, 208.05s/it]  4%|‚ñé         | 7/200 [24:21<11:07:03, 207.37s/it]  4%|‚ñç         | 8/200 [27:49<11:04:38, 207.70s/it]  4%|‚ñç         | 9/200 [31:19<11:02:47, 208.20s/it]  5%|‚ñå         | 10/200 [34:46<10:58:21, 207.90s/it]  6%|‚ñå         | 11/200 [38:14<10:55:14, 208.01s/it]  6%|‚ñå         | 12/200 [41:40<10:49:17, 207.22s/it]  6%|‚ñã         | 13/200 [45:08<10:46:49, 207.54s/it]  7%|‚ñã         | 14/200 [48:35<10:43:12, 207.49s/it]  8%|‚ñä         | 15/200 [52:01<10:37:58, 206.91s/it]  8%|‚ñä         | 16/200 [55:27<10:33:35, 206.61s/it]  8%|‚ñä         | 17/200 [58:54<10:30:34, 206.74s/it]  9%|‚ñâ         | 18/200 [1:02:23<10:29:20, 207.48s/it] 10%|‚ñâ         | 19/200 [1:05:51<10:26:12, 207.58s/it] 10%|‚ñà         | 20/200 [1:09:13<10:17:33, 205.85s/it] 10%|‚ñà         | 21/200 [1:12:41<10:16:34, 206.67s/it] 11%|‚ñà         | 22/200 [1:16:06<10:11:37, 206.16s/it] 12%|‚ñà‚ñè        | 23/200 [1:19:33<10:08:59, 206.44s/it] 12%|‚ñà‚ñè        | 24/200 [1:22:58<10:04:25, 206.06s/it] 12%|‚ñà‚ñé        | 25/200 [1:26:25<10:01:29, 206.22s/it] 13%|‚ñà‚ñé        | 26/200 [1:29:53<9:59:59, 206.89s/it]  14%|‚ñà‚ñé        | 27/200 [1:33:21<9:57:07, 207.09s/it] 14%|‚ñà‚ñç        | 28/200 [1:36:45<9:50:48, 206.10s/it] 14%|‚ñà‚ñç        | 29/200 [1:40:09<9:45:59, 205.61s/it] 15%|‚ñà‚ñå        | 30/200 [1:43:39<9:46:15, 206.91s/it] 16%|‚ñà‚ñå        | 31/200 [1:47:12<9:47:28, 208.57s/it] 16%|‚ñà‚ñå        | 32/200 [1:50:38<9:41:43, 207.76s/it] 16%|‚ñà‚ñã        | 33/200 [1:54:05<9:38:22, 207.80s/it] 17%|‚ñà‚ñã        | 34/200 [1:57:32<9:33:40, 207.35s/it] 18%|‚ñà‚ñä        | 35/200 [2:00:59<9:30:26, 207.44s/it] 18%|‚ñà‚ñä        | 36/200 [2:04:24<9:25:06, 206.75s/it] 18%|‚ñà‚ñä        | 37/200 [2:07:50<9:20:46, 206.42s/it] 19%|‚ñà‚ñâ        | 38/200 [2:11:18<9:18:42, 206.93s/it] 20%|‚ñà‚ñâ        | 39/200 [2:14:44<9:14:04, 206.49s/it] 20%|‚ñà‚ñà        | 40/200 [2:18:13<9:12:51, 207.32s/it] 20%|‚ñà‚ñà        | 41/200 [2:21:40<9:08:51, 207.11s/it] 21%|‚ñà‚ñà        | 42/200 [2:25:09<9:06:57, 207.71s/it] 22%|‚ñà‚ñà‚ñè       | 43/200 [2:28:34<9:01:21, 206.89s/it] 22%|‚ñà‚ñà‚ñè       | 44/200 [2:32:00<8:57:07, 206.59s/it] 22%|‚ñà‚ñà‚ñé       | 45/200 [2:35:29<8:55:58, 207.47s/it] 23%|‚ñà‚ñà‚ñé       | 46/200 [2:38:57<8:52:39, 207.53s/it] 24%|‚ñà‚ñà‚ñé       | 47/200 [2:42:22<8:47:19, 206.79s/it] 24%|‚ñà‚ñà‚ñç       | 48/200 [2:45:47<8:42:34, 206.28s/it] 24%|‚ñà‚ñà‚ñç       | 49/200 [2:49:14<8:39:23, 206.38s/it] 25%|‚ñà‚ñà‚ñå       | 50/200 [2:52:43<8:38:35, 207.43s/it] 26%|‚ñà‚ñà‚ñå       | 51/200 [2:56:12<8:35:56, 207.76s/it] 26%|‚ñà‚ñà‚ñå       | 52/200 [2:59:38<8:31:00, 207.17s/it] 26%|‚ñà‚ñà‚ñã       | 53/200 [3:03:07<8:29:04, 207.79s/it] 27%|‚ñà‚ñà‚ñã       | 54/200 [3:06:32<8:23:56, 207.10s/it] 28%|‚ñà‚ñà‚ñä       | 55/200 [3:10:02<8:22:21, 207.87s/it] 28%|‚ñà‚ñà‚ñä       | 56/200 [3:13:33<8:20:59, 208.75s/it] 28%|‚ñà‚ñà‚ñä       | 57/200 [3:17:01<8:16:44, 208.42s/it] 29%|‚ñà‚ñà‚ñâ       | 58/200 [3:20:26<8:11:00, 207.47s/it] 30%|‚ñà‚ñà‚ñâ       | 59/200 [3:23:53<8:07:07, 207.29s/it] 30%|‚ñà‚ñà‚ñà       | 60/200 [3:27:19<8:03:05, 207.04s/it] 30%|‚ñà‚ñà‚ñà       | 61/200 [3:30:44<7:58:19, 206.47s/it] 31%|‚ñà‚ñà‚ñà       | 62/200 [3:34:11<7:54:45, 206.42s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [3:37:39<7:52:28, 206.92s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [3:41:02<7:46:43, 205.91s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [3:44:29<7:44:07, 206.28s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [3:48:01<7:44:00, 207.77s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [3:51:28<7:40:31, 207.76s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [3:54:53<7:34:48, 206.73s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [3:58:23<7:33:45, 207.83s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [4:01:48<7:28:39, 207.07s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [4:05:15<7:24:37, 206.80s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [4:08:38<7:19:05, 205.82s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [4:12:06<7:16:43, 206.33s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [4:15:33<7:13:50, 206.59s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [4:18:58<7:09:26, 206.13s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [4:22:24<7:05:57, 206.11s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [4:26:00<7:08:53, 209.22s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [4:29:32<7:06:48, 209.90s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [4:33:03<7:04:03, 210.28s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [4:36:30<6:58:46, 209.39s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [4:39:32<6:38:52, 201.12s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [4:42:24<6:18:12, 192.31s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [4:45:19<6:04:50, 187.10s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [4:48:10<5:52:33, 182.36s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [4:51:04<5:44:43, 179.86s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [4:53:56<5:37:17, 177.52s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [4:56:48<5:31:00, 175.76s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [4:59:40<5:26:09, 174.73s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [5:02:39<5:25:37, 176.01s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [5:05:43<5:27:09, 178.45s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [5:08:45<5:25:51, 179.37s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [5:11:44<5:22:53, 179.38s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [5:14:49<5:22:56, 181.09s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [5:17:52<5:20:54, 181.65s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [5:20:54<5:18:05, 181.77s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [5:23:59<5:16:35, 182.65s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [5:27:07<5:16:03, 184.11s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [5:30:09<5:12:09, 183.62s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [5:33:12<5:08:57, 183.54s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [5:36:12<5:03:42, 182.22s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [5:39:16<5:01:33, 182.77s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [5:42:18<4:58:25, 182.71s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [5:45:20<4:54:59, 182.46s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [5:48:21<4:51:09, 181.97s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [5:51:22<4:47:54, 181.83s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [5:54:25<4:45:02, 181.94s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [5:57:27<4:42:05, 182.00s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [6:00:31<4:39:56, 182.57s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [6:03:34<4:37:17, 182.83s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [6:06:41<4:36:16, 184.18s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [6:09:48<4:34:10, 184.84s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [6:12:49<4:29:33, 183.79s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [6:15:55<4:27:24, 184.42s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [6:18:56<4:22:42, 183.29s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [6:21:58<4:19:19, 183.06s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [6:25:02<4:16:33, 183.26s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [6:28:04<4:13:09, 183.01s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [6:31:04<4:08:52, 182.10s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [6:34:09<4:06:58, 182.94s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [6:37:15<4:04:56, 183.71s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [6:40:23<4:03:48, 185.17s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [6:43:30<4:01:24, 185.70s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [6:46:32<3:56:54, 184.60s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [6:49:36<3:53:24, 184.27s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [6:52:40<3:50:27, 184.37s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [6:55:40<3:45:45, 183.05s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [6:58:46<3:43:42, 183.86s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [7:01:50<3:40:43, 183.93s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [7:04:54<3:37:28, 183.78s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [7:07:57<3:34:09, 183.56s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [7:11:02<3:31:43, 184.11s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [7:14:05<3:28:12, 183.71s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [7:17:09<3:25:27, 183.99s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [7:20:10<3:21:18, 183.01s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [7:23:12<3:18:01, 182.79s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [7:26:19<3:16:14, 183.98s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [7:29:23<3:13:11, 184.00s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [7:32:26<3:09:52, 183.75s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [7:35:31<3:07:03, 183.99s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [7:38:32<3:02:58, 182.98s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [7:41:32<2:59:14, 182.27s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [7:44:32<2:55:30, 181.56s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [7:47:34<2:52:37, 181.71s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [7:50:36<2:49:45, 181.88s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [7:53:41<2:47:27, 182.68s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [7:56:43<2:44:14, 182.49s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [7:59:38<2:39:10, 180.20s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [8:02:38<2:36:15, 180.29s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [8:05:40<2:33:30, 180.60s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [8:08:43<2:31:11, 181.43s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [8:11:44<2:27:56, 181.15s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [8:14:48<2:25:41, 182.12s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [8:17:51<2:22:48, 182.30s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [8:20:51<2:19:20, 181.76s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [8:23:55<2:16:43, 182.30s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [8:26:55<2:13:07, 181.54s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [8:29:56<2:10:00, 181.42s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [8:32:58<2:07:06, 181.59s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [8:36:01<2:04:26, 182.10s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [8:39:00<2:00:46, 181.17s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [8:42:05<1:58:31, 182.34s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [8:45:09<1:55:51, 182.95s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [8:48:14<1:53:05, 183.40s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [8:51:16<1:49:44, 182.89s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [8:54:17<1:46:26, 182.47s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [8:57:11<1:42:00, 180.01s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [8:59:59<1:36:58, 176.32s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [9:02:44<1:32:15, 173.00s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [9:05:30<1:28:13, 170.77s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [9:08:16<1:24:42, 169.41s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [9:11:05<1:21:48, 169.25s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [9:13:51<1:18:31, 168.26s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [9:16:35<1:15:11, 167.09s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [9:19:20<1:12:07, 166.45s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [9:22:07<1:09:21, 166.46s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [9:24:51<1:06:19, 165.83s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [9:27:36<1:03:25, 165.46s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [9:30:25<1:01:06, 166.64s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [9:33:15<58:39, 167.59s/it]   90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [9:36:03<55:55, 167.77s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [9:38:55<53:31, 169.04s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [9:41:46<50:55, 169.74s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [9:44:38<48:12, 170.17s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [9:47:31<45:37, 171.08s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [9:50:26<43:05, 172.38s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [9:53:18<40:12, 172.30s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [9:56:13<37:27, 172.89s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [9:59:08<34:44, 173.71s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [10:02:04<31:56, 174.25s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [10:04:55<28:54, 173.43s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [10:07:45<25:51, 172.42s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [10:10:30<22:41, 170.24s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [10:13:14<19:37, 168.28s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [10:15:58<16:42, 167.02s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [10:18:43<13:51, 166.22s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [10:21:27<11:03, 165.80s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [10:24:11<08:15, 165.08s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [10:26:56<05:29, 164.96s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [10:29:40<02:44, 164.89s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [10:32:23<00:00, 164.39s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [10:32:23<00:00, 189.72s/it]
Epoch: 0, Average Loss: 4.419497873836432, Trn Accuracy: 3.14%, lr: 0.0005
Average Val Loss: 4.385165504262417, Val_accuracy: 2.8
Epoch: 1, Average Loss: 4.382659377381444, Trn Accuracy: 3.21%, lr: 0.0004998766400914329
Average Val Loss: 4.363555461545534, Val_accuracy: 3.31
Epoch: 2, Average Loss: 4.374007097067543, Trn Accuracy: 3.46%, lr: 0.0004995066821070679
Average Val Loss: 4.401850489121449, Val_accuracy: 2.41
Epoch: 3, Average Loss: nan, Trn Accuracy: 1.50%, lr: 0.00049889049115077
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 4, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004980286753286195
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 5, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004969220851487844
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 6, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004955718126821722
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 7, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004939791904846868
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 8, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004921457902821577
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 9, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004900734214192357
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 10, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00048776412907378835
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 11, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00048522019223855637
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 12, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00048244412147206283
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 13, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00047943865642099525
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 14, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004762067631165049
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 15, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00047275163104709196
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 16, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004690766700109659
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 17, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00046518550675098597
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 18, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004610819813755038
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 19, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004567701435686405
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 20, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00045225424859373693
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 21, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004475387530939226
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 22, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004426283106939473
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 23, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004375277674076149
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 24, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00043224215685535287
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 25, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00042677669529663686
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 26, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004211367764821722
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 27, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00041532796633091297
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 28, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00040935599743717243
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 29, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00040322676341324415
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 30, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00039694631307311834
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 31, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0003905208444630327
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 32, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00038395669874474915
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 33, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00037726035393759286
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 34, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00037043841852542884
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 35, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0003634976249348867
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 36, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0003564448228912682
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 37, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00034928697265869515
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 38, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00034203113817116957
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 39, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0003346844800613229
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 40, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00032725424859373687
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 41, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00031974777650980735
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 42, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0003121724717912137
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 43, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0003045358103491357
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 44, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00029684532864643126
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 45, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0002891086162600578
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 46, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00028133330839107617
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 47, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0002735270783296286
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 48, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00026569762988232844
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 49, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00025785268976953217
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 50, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0002500000000000001
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 51, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00024214731023046803
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 52, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00023430237011767176
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 53, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0002264729216703715
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 54, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00021866669160892403
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 55, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00021089138373994235
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 56, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00020315467135356892
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 57, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0001954641896508645
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 58, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00018782752820878634
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 59, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00018025222349019276
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 60, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00017274575140626327
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 61, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0001653155199386772
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 62, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00015796886182883063
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 63, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00015071302734130486
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 64, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00014355517710873186
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 65, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00013650237506511334
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 66, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00012956158147457117
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 67, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0001227396460624072
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 68, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00011604330125525082
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 69, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00010947915553696737
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 70, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00010305368692688178
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 71, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.677323658675589e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 72, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.06440025628276e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 73, Average Loss: nan, Trn Accuracy: 1.00%, lr: 8.467203366908711e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 74, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.886322351782786e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 75, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.322330470336317e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 76, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.77578431446472e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 77, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.247223259238512e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 78, Average Loss: nan, Trn Accuracy: 1.00%, lr: 5.737168930605274e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 79, Average Loss: nan, Trn Accuracy: 1.00%, lr: 5.2461246906077416e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 80, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.7745751406263184e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 81, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.322985643135959e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 82, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.89180186244963e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 83, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.481449324901408e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 84, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.092332998903412e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 85, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.7248368952908065e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 86, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.379323688349517e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 87, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.056134357900478e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 88, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.755587852793717e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 89, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.4779807761443642e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 90, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.223587092621162e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 91, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.926578580764263e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 92, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.85420971784226e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 93, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.02080951531317e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 94, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.42818731782782e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 95, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.0779148512155855e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 96, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.971324671380559e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 97, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.1095088492300012e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 98, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.933178929321103e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 99, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.233599085671e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 100, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 101, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.233599085671e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 102, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.933178929321102e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 103, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.1095088492300007e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 104, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.9713246713805307e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 105, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.077914851215557e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 106, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.4281873178278475e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 107, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.020809515313142e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 108, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.854209717842205e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 109, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.926578580764207e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 110, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.223587092621159e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 111, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.4779807761443637e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 112, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.7555878527937136e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 113, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.0561343579004686e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 114, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.3793236883495076e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 115, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.724836895290808e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 116, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.0923329989034126e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 117, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.4814493249014084e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 118, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.89180186244962e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 119, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.322985643135948e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 120, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.774575140626305e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 121, Average Loss: nan, Trn Accuracy: 1.00%, lr: 5.2461246906077416e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 122, Average Loss: nan, Trn Accuracy: 1.00%, lr: 5.7371689306052684e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 123, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.247223259238507e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 124, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.775784314464706e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 125, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.322330470336302e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 126, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.886322351782783e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 127, Average Loss: nan, Trn Accuracy: 1.00%, lr: 8.4672033669087e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 128, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.06440025628276e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 129, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.677323658675587e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 130, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00010305368692688169
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 131, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00010947915553696727
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 132, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00011604330125525093
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 133, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00012273964606240723
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 134, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0001295615814745712
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 135, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00013650237506511326
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 136, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00014355517710873194
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 137, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0001507130273413049
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 138, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00015796886182883053
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 139, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00016531551993867713
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 140, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00017274575140626308
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 141, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0001802522234901926
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 142, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00018782752820878642
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 143, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00019546418965086441
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 144, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00020315467135356886
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 145, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00021089138373994227
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 146, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00021866669160892387
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 147, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0002264729216703715
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 148, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00023430237011767168
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 149, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00024214731023046793
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 150, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00024999999999999995
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 151, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00025785268976953195
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 152, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00026569762988232817
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 153, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0002735270783296286
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 154, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00028133330839107606
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 155, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0002891086162600577
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 156, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0002968453286464311
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 157, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00030453581034913554
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 158, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00031217247179121373
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 159, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0003197477765098073
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 160, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0003272542485937368
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 161, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00033468448006132275
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 162, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00034203113817116935
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 163, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.000349286972658695
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 164, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00035644482289126796
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 165, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00036349762493488645
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 166, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00037043841852542895
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 167, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00037726035393759297
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 168, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0003839566987447493
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 169, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00039052084446303275
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 170, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00039694631307311834
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 171, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00040322676341324415
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 172, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00040935599743717243
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 173, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00041532796633091297
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 174, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00042113677648217203
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 175, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00042677669529663675
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 176, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004322421568553529
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 177, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.000437527767407615
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 178, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004426283106939475
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 179, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004475387530939227
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 180, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004522542485937371
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 181, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00045677014356864065
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 182, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.000461081981375504
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 183, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00046518550675098613
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 184, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004690766700109661
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 185, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004727516310470923
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 186, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004762067631165052
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 187, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00047943865642099574
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 188, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004824441214720632
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 189, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00048522019223855674
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 190, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004877641290737888
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 191, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004900734214192361
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 192, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004921457902821582
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 193, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004939791904846872
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 194, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004955718126821726
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 195, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004969220851487848
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 196, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004980286753286198
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 197, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004988904911507704
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 198, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004995066821070683
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 199, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004998766400914333
Average Val Loss: nan, Val_accuracy: 1.0
Accuracy on the 10000 test images: 1.0%
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.013 MB uploadedwandb: / 0.013 MB of 0.046 MB uploadedwandb: - 0.046 MB of 0.046 MB uploadedwandb: \ 0.046 MB of 0.046 MB uploadedwandb: 
wandb: Run history:
wandb:     average_loss ‚ñÅ                                       
wandb: average_val_loss ‚ñÅ                                       
wandb:            epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:               lr ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:    test_accuracy ‚ñÅ
wandb:     trn_accuracy ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:     val_accuracy ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:     average_loss nan
wandb: average_val_loss nan
wandb:            epoch 199
wandb:               lr 0.0005
wandb:    test_accuracy 1.0
wandb:     trn_accuracy 1.0
wandb:     val_accuracy 1.0
wandb: 
wandb: üöÄ View run fast-puddle-31 at: https://wandb.ai/BDIC-DMML-2024/clip-linear-probe-classification/runs/ot5iz4h7
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/BDIC-DMML-2024/clip-linear-probe-classification
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240413_202158-ot5iz4h7/logs
Exception in thread ChkStopThr:
Traceback (most recent call last):
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self.run()
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/threading.py", line 870, in run
Exception in thread NetStatThr:
Traceback (most recent call last):
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/threading.py", line 932, in _bootstrap_inner
    self._target(*self._args, **self._kwargs)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 286, in check_stop_status
    self.run()
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/threading.py", line 870, in run
    self._loop_check_status(
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 224, in _loop_check_status
    self._target(*self._args, **self._kwargs)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 268, in check_network_status
    local_handle = request()
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 840, in deliver_stop_status
    self._loop_check_status(
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/wandb_run.py", line 224, in _loop_check_status
    local_handle = request()
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/interface/interface.py", line 848, in deliver_network_status
    return self._deliver_stop_status(status)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 494, in _deliver_stop_status
    return self._deliver_network_status(status)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 510, in _deliver_network_status
    return self._deliver_record(record)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 459, in _deliver_record
    return self._deliver_record(record)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/interface/interface_shared.py", line 459, in _deliver_record
    handle = mailbox._deliver_record(record, interface=self)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py", line 455, in _deliver_record
    handle = mailbox._deliver_record(record, interface=self)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/lib/mailbox.py", line 455, in _deliver_record
    interface._publish(record)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    interface._publish(record)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/interface/interface_sock.py", line 51, in _publish
    self._sock_client.send_record_publish(record)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 221, in send_record_publish
    self._sock_client.send_record_publish(record)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 221, in send_record_publish
    self.send_server_request(server_req)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self.send_server_request(server_req)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 155, in send_server_request
    self._send_message(msg)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._send_message(msg)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 152, in _send_message
    self._sendall_with_error_handle(header + data)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    self._sendall_with_error_handle(header + data)
  File "/data0/user/gsli/.conda/envs/test/lib/python3.8/site-packages/wandb/sdk/lib/sock_client.py", line 130, in _sendall_with_error_handle
    sent = self._sock.send(data)
BrokenPipeError: [Errno 32] Broken pipe
    sent = self._sock.send(data)
BrokenPipeError: [Errno 32] Broken pipe
