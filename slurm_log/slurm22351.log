wandb: Currently logged in as: ligengchengucd (BDIC-DMML-2024). Use `wandb login --relogin` to force relogin
wandb: Tracking run with wandb version 0.16.6
wandb: Run data is saved locally in /data0/user/gsli/Classifiers-enhanced-by-pre-training/wandb/run-20240413_202115-dwk0ppbj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run trim-vortex-30
wandb: ‚≠êÔ∏è View project at https://wandb.ai/BDIC-DMML-2024/clip-linear-probe-classification
wandb: üöÄ View run at https://wandb.ai/BDIC-DMML-2024/clip-linear-probe-classification/runs/dwk0ppbj
Files already downloaded and verified
Files already downloaded and verified
  0%|          | 0/200 [00:00<?, ?it/s]  0%|          | 1/200 [03:55<13:01:39, 235.68s/it]  1%|          | 2/200 [08:05<13:24:44, 243.86s/it]  2%|‚ñè         | 3/200 [12:20<13:38:11, 249.19s/it]  2%|‚ñè         | 4/200 [16:35<13:41:34, 251.50s/it]  2%|‚ñé         | 5/200 [20:50<13:40:48, 252.56s/it]  3%|‚ñé         | 6/200 [25:04<13:38:13, 253.06s/it]  4%|‚ñé         | 7/200 [29:22<13:39:26, 254.75s/it]  4%|‚ñç         | 8/200 [33:33<13:31:48, 253.69s/it]  4%|‚ñç         | 9/200 [37:51<13:31:40, 254.98s/it]  5%|‚ñå         | 10/200 [41:50<13:11:43, 250.02s/it]  6%|‚ñå         | 11/200 [46:04<13:10:47, 251.04s/it]  6%|‚ñå         | 12/200 [50:10<13:02:04, 249.60s/it]  6%|‚ñã         | 13/200 [54:23<13:00:59, 250.58s/it]  7%|‚ñã         | 14/200 [58:39<13:01:49, 252.20s/it]  8%|‚ñä         | 15/200 [1:02:50<12:57:01, 252.01s/it]  8%|‚ñä         | 16/200 [1:07:03<12:53:14, 252.14s/it]  8%|‚ñä         | 17/200 [1:11:15<12:49:19, 252.24s/it]  9%|‚ñâ         | 18/200 [1:15:27<12:44:47, 252.13s/it] 10%|‚ñâ         | 19/200 [1:19:40<12:40:57, 252.25s/it] 10%|‚ñà         | 20/200 [1:23:46<12:31:25, 250.47s/it] 10%|‚ñà         | 21/200 [1:27:57<12:27:54, 250.70s/it] 11%|‚ñà         | 22/200 [1:31:56<12:13:35, 247.28s/it] 12%|‚ñà‚ñè        | 23/200 [1:36:08<12:13:20, 248.59s/it] 12%|‚ñà‚ñè        | 24/200 [1:40:22<12:13:52, 250.18s/it] 12%|‚ñà‚ñé        | 25/200 [1:44:40<12:16:12, 252.41s/it] 13%|‚ñà‚ñé        | 26/200 [1:48:55<12:14:35, 253.31s/it] 14%|‚ñà‚ñé        | 27/200 [1:53:09<12:10:44, 253.43s/it] 14%|‚ñà‚ñç        | 28/200 [1:57:23<12:07:10, 253.66s/it] 14%|‚ñà‚ñç        | 29/200 [2:01:39<12:04:50, 254.33s/it] 15%|‚ñà‚ñå        | 30/200 [2:05:53<12:00:27, 254.28s/it] 16%|‚ñà‚ñå        | 31/200 [2:09:51<11:42:34, 249.43s/it] 16%|‚ñà‚ñå        | 32/200 [2:13:53<11:32:28, 247.31s/it] 16%|‚ñà‚ñã        | 33/200 [2:18:07<11:33:40, 249.22s/it] 17%|‚ñà‚ñã        | 34/200 [2:22:20<11:32:29, 250.30s/it] 18%|‚ñà‚ñä        | 35/200 [2:26:32<11:29:42, 250.80s/it] 18%|‚ñà‚ñä        | 36/200 [2:30:50<11:31:40, 253.05s/it] 18%|‚ñà‚ñä        | 37/200 [2:35:06<11:30:07, 254.03s/it] 19%|‚ñà‚ñâ        | 38/200 [2:39:21<11:25:54, 254.04s/it] 20%|‚ñà‚ñâ        | 39/200 [2:43:33<11:20:31, 253.61s/it] 20%|‚ñà‚ñà        | 40/200 [2:47:48<11:17:15, 253.97s/it] 20%|‚ñà‚ñà        | 41/200 [2:51:48<11:01:49, 249.75s/it] 21%|‚ñà‚ñà        | 42/200 [2:56:03<11:02:03, 251.41s/it] 22%|‚ñà‚ñà‚ñè       | 43/200 [3:00:05<10:50:27, 248.58s/it] 22%|‚ñà‚ñà‚ñè       | 44/200 [3:04:17<10:49:06, 249.65s/it] 22%|‚ñà‚ñà‚ñé       | 45/200 [3:08:33<10:49:39, 251.48s/it] 23%|‚ñà‚ñà‚ñé       | 46/200 [3:12:49<10:48:50, 252.80s/it] 24%|‚ñà‚ñà‚ñé       | 47/200 [3:17:05<10:47:27, 253.91s/it] 24%|‚ñà‚ñà‚ñç       | 48/200 [3:21:16<10:41:02, 253.04s/it] 24%|‚ñà‚ñà‚ñç       | 49/200 [3:25:25<10:33:48, 251.84s/it] 25%|‚ñà‚ñà‚ñå       | 50/200 [3:29:36<10:28:54, 251.56s/it] 26%|‚ñà‚ñà‚ñå       | 51/200 [3:33:46<10:23:13, 250.96s/it] 26%|‚ñà‚ñà‚ñå       | 52/200 [3:37:55<10:17:36, 250.38s/it] 26%|‚ñà‚ñà‚ñã       | 53/200 [3:41:59<10:08:32, 248.39s/it] 27%|‚ñà‚ñà‚ñã       | 54/200 [3:46:14<10:09:44, 250.58s/it] 28%|‚ñà‚ñà‚ñä       | 55/200 [3:50:26<10:06:30, 250.97s/it] 28%|‚ñà‚ñà‚ñä       | 56/200 [3:54:41<10:05:04, 252.11s/it] 28%|‚ñà‚ñà‚ñä       | 57/200 [3:58:57<10:03:36, 253.26s/it] 29%|‚ñà‚ñà‚ñâ       | 58/200 [4:03:15<10:02:42, 254.67s/it] 30%|‚ñà‚ñà‚ñâ       | 59/200 [4:07:26<9:55:46, 253.52s/it]  30%|‚ñà‚ñà‚ñà       | 60/200 [4:11:39<9:51:00, 253.29s/it] 30%|‚ñà‚ñà‚ñà       | 61/200 [4:15:56<9:49:28, 254.45s/it] 31%|‚ñà‚ñà‚ñà       | 62/200 [4:19:59<9:37:51, 251.25s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 63/200 [4:24:06<9:30:31, 249.86s/it] 32%|‚ñà‚ñà‚ñà‚ñè      | 64/200 [4:28:25<9:32:14, 252.46s/it] 32%|‚ñà‚ñà‚ñà‚ñé      | 65/200 [4:32:45<9:33:42, 254.98s/it] 33%|‚ñà‚ñà‚ñà‚ñé      | 66/200 [4:37:02<9:30:23, 255.40s/it] 34%|‚ñà‚ñà‚ñà‚ñé      | 67/200 [4:41:17<9:26:00, 255.35s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 68/200 [4:45:29<9:19:27, 254.30s/it] 34%|‚ñà‚ñà‚ñà‚ñç      | 69/200 [4:49:43<9:15:06, 254.25s/it] 35%|‚ñà‚ñà‚ñà‚ñå      | 70/200 [4:53:51<9:06:51, 252.39s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 71/200 [4:58:00<9:00:35, 251.44s/it] 36%|‚ñà‚ñà‚ñà‚ñå      | 72/200 [5:02:04<8:51:33, 249.17s/it] 36%|‚ñà‚ñà‚ñà‚ñã      | 73/200 [5:06:26<8:55:19, 252.91s/it] 37%|‚ñà‚ñà‚ñà‚ñã      | 74/200 [5:10:32<8:46:42, 250.81s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 75/200 [5:14:55<8:49:59, 254.40s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 76/200 [5:19:20<8:52:23, 257.61s/it] 38%|‚ñà‚ñà‚ñà‚ñä      | 77/200 [5:23:41<8:50:18, 258.68s/it] 39%|‚ñà‚ñà‚ñà‚ñâ      | 78/200 [5:28:04<8:48:40, 260.00s/it] 40%|‚ñà‚ñà‚ñà‚ñâ      | 79/200 [5:32:22<8:43:03, 259.37s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 80/200 [5:36:32<8:33:01, 256.51s/it] 40%|‚ñà‚ñà‚ñà‚ñà      | 81/200 [5:40:39<8:23:29, 253.86s/it] 41%|‚ñà‚ñà‚ñà‚ñà      | 82/200 [5:44:42<8:12:32, 250.45s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 83/200 [5:48:56<8:10:50, 251.72s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñè     | 84/200 [5:52:52<7:57:30, 246.99s/it] 42%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 85/200 [5:57:07<7:57:30, 249.13s/it] 43%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 86/200 [6:01:24<7:57:49, 251.49s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñé     | 87/200 [6:05:38<7:55:15, 252.35s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 88/200 [6:09:54<7:53:02, 253.42s/it] 44%|‚ñà‚ñà‚ñà‚ñà‚ñç     | 89/200 [6:14:09<7:50:03, 254.08s/it] 45%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 90/200 [6:18:23<7:45:38, 253.99s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 91/200 [6:22:40<7:42:44, 254.72s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñå     | 92/200 [6:26:41<7:31:03, 250.59s/it] 46%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 93/200 [6:30:50<7:26:11, 250.20s/it] 47%|‚ñà‚ñà‚ñà‚ñà‚ñã     | 94/200 [6:34:49<7:16:20, 246.99s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 95/200 [6:39:06<7:17:03, 249.74s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 96/200 [6:43:21<7:16:01, 251.56s/it] 48%|‚ñà‚ñà‚ñà‚ñà‚ñä     | 97/200 [6:47:35<7:12:50, 252.14s/it] 49%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 98/200 [6:51:45<7:07:50, 251.67s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñâ     | 99/200 [6:55:59<7:04:33, 252.21s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 100/200 [7:00:13<7:01:24, 252.84s/it] 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 101/200 [7:04:27<6:57:26, 252.99s/it] 51%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 102/200 [7:08:30<6:48:45, 250.26s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 103/200 [7:12:37<6:42:48, 249.16s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè    | 104/200 [7:16:37<6:34:17, 246.43s/it] 52%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 105/200 [7:20:53<6:34:27, 249.13s/it] 53%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 106/200 [7:25:07<6:32:57, 250.83s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé    | 107/200 [7:29:22<6:30:26, 251.90s/it] 54%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 108/200 [7:33:36<6:27:31, 252.74s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç    | 109/200 [7:37:51<6:24:12, 253.32s/it] 55%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 110/200 [7:42:04<6:19:48, 253.21s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 111/200 [7:46:15<6:14:39, 252.58s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå    | 112/200 [7:50:23<6:08:12, 251.05s/it] 56%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 113/200 [7:54:31<6:02:39, 250.11s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã    | 114/200 [7:58:27<5:52:39, 246.04s/it] 57%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 115/200 [8:02:35<5:49:13, 246.51s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 116/200 [8:06:43<5:45:39, 246.90s/it] 58%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä    | 117/200 [8:10:55<5:43:43, 248.47s/it] 59%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 118/200 [8:15:06<5:40:45, 249.34s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ    | 119/200 [8:19:17<5:37:06, 249.71s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 120/200 [8:23:28<5:33:39, 250.24s/it] 60%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 121/200 [8:27:40<5:30:13, 250.81s/it] 61%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà    | 122/200 [8:31:55<5:27:29, 251.92s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 123/200 [8:35:56<5:19:10, 248.71s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè   | 124/200 [8:39:57<5:12:06, 246.41s/it] 62%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 125/200 [8:44:08<5:09:53, 247.91s/it] 63%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 126/200 [8:48:19<5:06:38, 248.63s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé   | 127/200 [8:52:31<5:03:53, 249.78s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 128/200 [8:56:40<4:59:15, 249.38s/it] 64%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç   | 129/200 [9:00:32<4:49:04, 244.29s/it] 65%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 130/200 [9:04:24<4:40:40, 240.58s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 131/200 [9:08:21<4:35:26, 239.52s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå   | 132/200 [9:12:14<4:29:24, 237.71s/it] 66%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 133/200 [9:16:01<4:21:36, 234.27s/it] 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 134/200 [9:19:49<4:15:46, 232.53s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 135/200 [9:23:30<4:08:12, 229.12s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 136/200 [9:27:21<4:05:00, 229.70s/it] 68%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä   | 137/200 [9:31:18<4:03:15, 231.68s/it] 69%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 138/200 [9:35:16<4:01:33, 233.76s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ   | 139/200 [9:39:12<3:58:22, 234.47s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 140/200 [9:43:13<3:56:20, 236.35s/it] 70%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 141/200 [9:47:21<3:55:42, 239.70s/it] 71%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà   | 142/200 [9:51:29<3:54:12, 242.28s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 143/200 [9:55:33<3:50:34, 242.71s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 144/200 [9:59:30<3:44:59, 241.07s/it] 72%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 145/200 [10:03:31<3:41:00, 241.10s/it] 73%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 146/200 [10:07:10<3:30:57, 234.39s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé  | 147/200 [10:10:41<3:20:46, 227.29s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 148/200 [10:14:08<3:11:56, 221.47s/it] 74%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç  | 149/200 [10:17:34<3:04:04, 216.56s/it] 75%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 150/200 [10:21:03<2:58:44, 214.49s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 151/200 [10:24:33<2:54:05, 213.18s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå  | 152/200 [10:28:04<2:49:50, 212.30s/it] 76%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 153/200 [10:31:29<2:44:37, 210.16s/it] 77%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã  | 154/200 [10:34:36<2:35:51, 203.29s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 155/200 [10:38:02<2:33:08, 204.18s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 156/200 [10:41:28<2:29:58, 204.51s/it] 78%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä  | 157/200 [10:44:54<2:26:57, 205.06s/it] 79%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 158/200 [10:48:20<2:23:49, 205.47s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ  | 159/200 [10:51:45<2:20:13, 205.22s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 160/200 [10:55:12<2:17:05, 205.64s/it] 80%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 161/200 [10:58:41<2:14:27, 206.86s/it] 81%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà  | 162/200 [11:02:10<2:11:23, 207.47s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 163/200 [11:05:12<2:03:16, 199.91s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè | 164/200 [11:08:37<2:00:47, 201.31s/it] 82%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 165/200 [11:12:03<1:58:17, 202.79s/it] 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 166/200 [11:15:29<1:55:28, 203.77s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 167/200 [11:18:55<1:52:21, 204.29s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 168/200 [11:22:21<1:49:17, 204.92s/it] 84%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç | 169/200 [11:25:50<1:46:29, 206.12s/it] 85%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 170/200 [11:29:20<1:43:40, 207.36s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 171/200 [11:32:51<1:40:38, 208.21s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå | 172/200 [11:35:55<1:33:52, 201.15s/it] 86%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 173/200 [11:39:22<1:31:16, 202.84s/it] 87%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã | 174/200 [11:42:48<1:28:19, 203.82s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 175/200 [11:46:14<1:25:11, 204.48s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 176/200 [11:49:42<1:22:10, 205.42s/it] 88%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä | 177/200 [11:53:04<1:18:24, 204.53s/it] 89%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 178/200 [11:56:32<1:15:19, 205.44s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ | 179/200 [11:59:59<1:12:03, 205.86s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 180/200 [12:03:27<1:08:53, 206.67s/it] 90%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 181/200 [12:06:40<1:04:10, 202.65s/it] 91%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà | 182/200 [12:10:03<1:00:46, 202.56s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 183/200 [12:13:27<57:32, 203.11s/it]   92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè| 184/200 [12:16:53<54:22, 203.89s/it] 92%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 185/200 [12:20:19<51:10, 204.69s/it] 93%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 186/200 [12:23:49<48:05, 206.13s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé| 187/200 [12:27:17<44:46, 206.65s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 188/200 [12:30:45<41:25, 207.09s/it] 94%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç| 189/200 [12:34:10<37:52, 206.63s/it] 95%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 190/200 [12:37:30<34:05, 204.58s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 191/200 [12:40:41<30:02, 200.27s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñå| 192/200 [12:44:08<26:58, 202.32s/it] 96%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 193/200 [12:47:33<23:43, 203.30s/it] 97%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã| 194/200 [12:51:00<20:25, 204.22s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 195/200 [12:54:25<17:02, 204.56s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 196/200 [12:57:50<13:38, 204.62s/it] 98%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä| 197/200 [13:01:16<10:15, 205.17s/it] 99%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 198/200 [13:04:43<06:51, 205.68s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñâ| 199/200 [13:08:09<03:25, 205.86s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [13:11:11<00:00, 198.57s/it]100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [13:11:11<00:00, 237.36s/it]
Epoch: 0, Average Loss: 4.25061331160914, Trn Accuracy: 5.62%, lr: 0.0005
Average Val Loss: 4.001941041101383, Val_accuracy: 7.8
Epoch: 1, Average Loss: 3.9590016500637555, Trn Accuracy: 9.15%, lr: 0.0004998766400914329
Average Val Loss: 3.87294633479058, Val_accuracy: 10.08
Epoch: 2, Average Loss: 3.872654610167677, Trn Accuracy: 10.49%, lr: 0.0004995066821070679
Average Val Loss: 3.8398032188415527, Val_accuracy: 10.68
Epoch: 3, Average Loss: 3.821852113492192, Trn Accuracy: 11.53%, lr: 0.00049889049115077
Average Val Loss: 3.8279123306274414, Val_accuracy: 10.47
Epoch: 4, Average Loss: 3.7909697755076253, Trn Accuracy: 12.13%, lr: 0.0004980286753286195
Average Val Loss: 3.7512124490134324, Val_accuracy: 12.19
Epoch: 5, Average Loss: 3.7570728349228637, Trn Accuracy: 12.58%, lr: 0.0004969220851487844
Average Val Loss: 3.759273933458932, Val_accuracy: 12.43
Epoch: 6, Average Loss: 3.72900058743291, Trn Accuracy: 12.85%, lr: 0.0004955718126821722
Average Val Loss: 3.711740216122398, Val_accuracy: 12.87
Epoch: 7, Average Loss: 3.6903594096247763, Trn Accuracy: 13.45%, lr: 0.0004939791904846868
Average Val Loss: 3.659537768062157, Val_accuracy: 13.71
Epoch: 8, Average Loss: 3.6543325174349945, Trn Accuracy: 13.95%, lr: 0.0004921457902821577
Average Val Loss: 3.6417001078400433, Val_accuracy: 14.17
Epoch: 9, Average Loss: 3.6150490270255093, Trn Accuracy: 14.68%, lr: 0.0004900734214192357
Average Val Loss: 3.594877943207946, Val_accuracy: 14.73
Epoch: 10, Average Loss: 3.602516124804561, Trn Accuracy: 14.62%, lr: 0.00048776412907378835
Average Val Loss: 3.5666174254839933, Val_accuracy: 15.27
Epoch: 11, Average Loss: 3.5669582811788247, Trn Accuracy: 15.25%, lr: 0.00048522019223855637
Average Val Loss: 3.5530183858509305, Val_accuracy: 15.77
Epoch: 12, Average Loss: 3.5572041810130157, Trn Accuracy: 15.28%, lr: 0.00048244412147206283
Average Val Loss: 3.531582409822488, Val_accuracy: 15.47
Epoch: 13, Average Loss: 3.538425832510756, Trn Accuracy: 15.65%, lr: 0.00047943865642099525
Average Val Loss: 3.4992301403721675, Val_accuracy: 16.42
Epoch: 14, Average Loss: 3.5169560391301165, Trn Accuracy: 15.86%, lr: 0.0004762067631165049
Average Val Loss: 3.517201499093937, Val_accuracy: 16.04
Epoch: 15, Average Loss: 3.504663149007974, Trn Accuracy: 16.11%, lr: 0.00047275163104709196
Average Val Loss: 3.5137587348117103, Val_accuracy: 15.72
Epoch: 16, Average Loss: 3.4867000960694337, Trn Accuracy: 16.33%, lr: 0.0004690766700109659
Average Val Loss: 3.484014115756071, Val_accuracy: 16.47
Epoch: 17, Average Loss: 3.4898356637253927, Trn Accuracy: 16.51%, lr: 0.00046518550675098597
Average Val Loss: 3.4791892329348793, Val_accuracy: 16.49
Epoch: 18, Average Loss: 3.469581459276973, Trn Accuracy: 16.59%, lr: 0.0004610819813755038
Average Val Loss: 3.4370845722246774, Val_accuracy: 16.99
Epoch: 19, Average Loss: 3.458218695637517, Trn Accuracy: 17.06%, lr: 0.0004567701435686405
Average Val Loss: 3.455421363251119, Val_accuracy: 17.05
Epoch: 20, Average Loss: 3.4462478237030223, Trn Accuracy: 17.18%, lr: 0.00045225424859373693
Average Val Loss: 3.429683618907687, Val_accuracy: 17.22
Epoch: 21, Average Loss: 3.4415397849707556, Trn Accuracy: 17.31%, lr: 0.0004475387530939226
Average Val Loss: 3.41886141330381, Val_accuracy: 17.5
Epoch: 22, Average Loss: 3.432503253126297, Trn Accuracy: 17.29%, lr: 0.0004426283106939473
Average Val Loss: 3.4100721063493173, Val_accuracy: 17.79
Epoch: 23, Average Loss: 3.4171028792286835, Trn Accuracy: 17.71%, lr: 0.0004375277674076149
Average Val Loss: 3.423296668861486, Val_accuracy: 17.31
Epoch: 24, Average Loss: 3.407694558366038, Trn Accuracy: 17.80%, lr: 0.00043224215685535287
Average Val Loss: 3.4039791656445852, Val_accuracy: 17.71
Epoch: 25, Average Loss: 3.399782832057331, Trn Accuracy: 18.07%, lr: 0.00042677669529663686
Average Val Loss: 3.380468175381045, Val_accuracy: 18.39
Epoch: 26, Average Loss: 3.3894328629246915, Trn Accuracy: 18.21%, lr: 0.0004211367764821722
Average Val Loss: 3.3993590572212318, Val_accuracy: 17.75
Epoch: 27, Average Loss: 3.382390654506013, Trn Accuracy: 18.18%, lr: 0.00041532796633091297
Average Val Loss: 3.3648506508597844, Val_accuracy: 18.77
Epoch: 28, Average Loss: 3.3759420603608934, Trn Accuracy: 18.33%, lr: 0.00040935599743717243
Average Val Loss: 3.4103374933894677, Val_accuracy: 17.28
Epoch: 29, Average Loss: 3.367460704078309, Trn Accuracy: 18.57%, lr: 0.00040322676341324415
Average Val Loss: 3.3875367822526377, Val_accuracy: 18.5
Epoch: 30, Average Loss: 3.3662658362342905, Trn Accuracy: 18.56%, lr: 0.00039694631307311834
Average Val Loss: 3.392268159721471, Val_accuracy: 18.37
Epoch: 31, Average Loss: 3.357731796301211, Trn Accuracy: 18.63%, lr: 0.0003905208444630327
Average Val Loss: 3.3627747553813307, Val_accuracy: 18.61
Epoch: 32, Average Loss: 3.356609650694143, Trn Accuracy: 18.75%, lr: 0.00038395669874474915
Average Val Loss: 3.357887011540087, Val_accuracy: 18.86
Epoch: 33, Average Loss: 3.350805286401377, Trn Accuracy: 18.80%, lr: 0.00037726035393759286
Average Val Loss: 3.4204258556607403, Val_accuracy: 17.57
Epoch: 34, Average Loss: 3.3458845097416887, Trn Accuracy: 19.06%, lr: 0.00037043841852542884
Average Val Loss: 3.369451559042629, Val_accuracy: 19.17
Epoch: 35, Average Loss: 3.3367339345974663, Trn Accuracy: 19.22%, lr: 0.0003634976249348867
Average Val Loss: 3.334752369530593, Val_accuracy: 19.09
Epoch: 36, Average Loss: 3.326316084724646, Trn Accuracy: 19.25%, lr: 0.0003564448228912682
Average Val Loss: 3.3352750947203815, Val_accuracy: 19.3
Epoch: 37, Average Loss: 3.325510017407207, Trn Accuracy: 19.33%, lr: 0.00034928697265869515
Average Val Loss: 3.337394086620476, Val_accuracy: 19.24
Epoch: 38, Average Loss: 3.3199388729497645, Trn Accuracy: 19.54%, lr: 0.00034203113817116957
Average Val Loss: 3.341144145289554, Val_accuracy: 19.22
Epoch: 39, Average Loss: 3.3214728794158837, Trn Accuracy: 19.49%, lr: 0.0003346844800613229
Average Val Loss: 3.3412722726411457, Val_accuracy: 19.01
Epoch: 40, Average Loss: 3.307691427846305, Trn Accuracy: 19.66%, lr: 0.00032725424859373687
Average Val Loss: 3.3294943224025677, Val_accuracy: 19.61
Epoch: 41, Average Loss: 3.3098507239795723, Trn Accuracy: 19.34%, lr: 0.00031974777650980735
Average Val Loss: 3.331042805804482, Val_accuracy: 19.31
Epoch: 42, Average Loss: 3.3022928847291597, Trn Accuracy: 19.69%, lr: 0.0003121724717912137
Average Val Loss: 3.3069058973577956, Val_accuracy: 19.52
Epoch: 43, Average Loss: 3.3028203207083022, Trn Accuracy: 19.68%, lr: 0.0003045358103491357
Average Val Loss: 3.3336754539344886, Val_accuracy: 19.08
Epoch: 44, Average Loss: 3.2899944233818177, Trn Accuracy: 19.95%, lr: 0.00029684532864643126
Average Val Loss: 3.293837818918349, Val_accuracy: 19.7
Epoch: 45, Average Loss: 3.2853101693784086, Trn Accuracy: 20.09%, lr: 0.0002891086162600578
Average Val Loss: 3.3300138425223436, Val_accuracy: 19.18
Epoch: 46, Average Loss: 3.273568692679603, Trn Accuracy: 20.38%, lr: 0.00028133330839107617
Average Val Loss: 3.3245320621925063, Val_accuracy: 19.09
Epoch: 47, Average Loss: 3.266306347740344, Trn Accuracy: 20.33%, lr: 0.0002735270783296286
Average Val Loss: 3.3001869056798236, Val_accuracy: 19.38
Epoch: 48, Average Loss: 3.266463228688834, Trn Accuracy: 20.25%, lr: 0.00026569762988232844
Average Val Loss: 3.2896106062056143, Val_accuracy: 19.82
Epoch: 49, Average Loss: 3.2634139578944197, Trn Accuracy: 20.48%, lr: 0.00025785268976953217
Average Val Loss: 3.327021598815918, Val_accuracy: 19.07
Epoch: 50, Average Loss: 3.2596464606519704, Trn Accuracy: 20.44%, lr: 0.0002500000000000001
Average Val Loss: 3.2828541677209397, Val_accuracy: 19.83
Epoch: 51, Average Loss: 3.2471706669170635, Trn Accuracy: 20.61%, lr: 0.00024214731023046803
Average Val Loss: 3.2784736850593665, Val_accuracy: 19.91
Epoch: 52, Average Loss: 3.2408906171877927, Trn Accuracy: 20.57%, lr: 0.00023430237011767176
Average Val Loss: 3.2635151042213923, Val_accuracy: 20.13
Epoch: 53, Average Loss: 3.2363318262008813, Trn Accuracy: 20.62%, lr: 0.0002264729216703715
Average Val Loss: 3.2575554666639883, Val_accuracy: 20.28
Epoch: 54, Average Loss: 3.227286431736078, Trn Accuracy: 20.84%, lr: 0.00021866669160892403
Average Val Loss: 3.2451844215393066, Val_accuracy: 20.11
Epoch: 55, Average Loss: 3.2169993959676724, Trn Accuracy: 21.12%, lr: 0.00021089138373994235
Average Val Loss: 3.265423587605923, Val_accuracy: 19.75
Epoch: 56, Average Loss: 3.214784707505101, Trn Accuracy: 21.03%, lr: 0.00020315467135356892
Average Val Loss: 3.245281491098525, Val_accuracy: 20.67
Epoch: 57, Average Loss: 3.2038893113121056, Trn Accuracy: 21.22%, lr: 0.0001954641896508645
Average Val Loss: 3.2308549488647076, Val_accuracy: 20.49
Epoch: 58, Average Loss: 3.196737360268736, Trn Accuracy: 21.50%, lr: 0.00018782752820878634
Average Val Loss: 3.2374551416952397, Val_accuracy: 20.38
Epoch: 59, Average Loss: 3.186451011572402, Trn Accuracy: 21.52%, lr: 0.00018025222349019276
Average Val Loss: 3.2311937718451778, Val_accuracy: 20.71
Epoch: 60, Average Loss: 3.1797343481082123, Trn Accuracy: 21.55%, lr: 0.00017274575140626327
Average Val Loss: 3.2249176985100854, Val_accuracy: 20.9
Epoch: 61, Average Loss: 3.1741631031036377, Trn Accuracy: 21.89%, lr: 0.0001653155199386772
Average Val Loss: 3.22296501714972, Val_accuracy: 20.76
Epoch: 62, Average Loss: 3.1656805478726713, Trn Accuracy: 21.85%, lr: 0.00015796886182883063
Average Val Loss: 3.214971693256233, Val_accuracy: 21.18
Epoch: 63, Average Loss: 3.1611099128905957, Trn Accuracy: 21.89%, lr: 0.00015071302734130486
Average Val Loss: 3.1919984394990943, Val_accuracy: 21.3
Epoch: 64, Average Loss: 3.1535904750275536, Trn Accuracy: 22.18%, lr: 0.00014355517710873186
Average Val Loss: 3.189127025724966, Val_accuracy: 21.83
Epoch: 65, Average Loss: 3.144447335039084, Trn Accuracy: 22.30%, lr: 0.00013650237506511334
Average Val Loss: 3.179905013193058, Val_accuracy: 21.93
Epoch: 66, Average Loss: 3.1380824418113638, Trn Accuracy: 22.53%, lr: 0.00012956158147457117
Average Val Loss: 3.2241113517857807, Val_accuracy: 21.07
Epoch: 67, Average Loss: 3.1333877011990774, Trn Accuracy: 22.52%, lr: 0.0001227396460624072
Average Val Loss: 3.1659097309353985, Val_accuracy: 21.69
Epoch: 68, Average Loss: 3.1226846547172475, Trn Accuracy: 22.58%, lr: 0.00011604330125525082
Average Val Loss: 3.166766703883304, Val_accuracy: 21.98
Epoch: 69, Average Loss: 3.1174641394386655, Trn Accuracy: 22.79%, lr: 0.00010947915553696737
Average Val Loss: 3.2073786530313613, Val_accuracy: 20.9
Epoch: 70, Average Loss: 3.109369812682033, Trn Accuracy: 22.94%, lr: 0.00010305368692688178
Average Val Loss: 3.1566295744497563, Val_accuracy: 22.16
Epoch: 71, Average Loss: 3.1062030571337327, Trn Accuracy: 23.01%, lr: 9.677323658675589e-05
Average Val Loss: 3.15163941021207, Val_accuracy: 22.25
Epoch: 72, Average Loss: 3.0938652650997662, Trn Accuracy: 23.00%, lr: 9.06440025628276e-05
Average Val Loss: 3.1438540114632136, Val_accuracy: 22.09
Epoch: 73, Average Loss: 3.0887403747144218, Trn Accuracy: 23.24%, lr: 8.467203366908711e-05
Average Val Loss: 3.1305020670347576, Val_accuracy: 22.24
Epoch: 74, Average Loss: 3.0816402869483532, Trn Accuracy: 23.42%, lr: 7.886322351782786e-05
Average Val Loss: 3.131210402597355, Val_accuracy: 22.52
Epoch: 75, Average Loss: 3.0762547509738813, Trn Accuracy: 23.66%, lr: 7.322330470336317e-05
Average Val Loss: 3.1400406420985356, Val_accuracy: 22.45
Epoch: 76, Average Loss: 3.07514698741535, Trn Accuracy: 23.61%, lr: 6.77578431446472e-05
Average Val Loss: 3.13574284541456, Val_accuracy: 22.36
Epoch: 77, Average Loss: 3.069045693729632, Trn Accuracy: 23.70%, lr: 6.247223259238512e-05
Average Val Loss: 3.127690306192712, Val_accuracy: 22.37
Epoch: 78, Average Loss: nan, Trn Accuracy: 17.55%, lr: 5.737168930605274e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 79, Average Loss: nan, Trn Accuracy: 1.00%, lr: 5.2461246906077416e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 80, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.7745751406263184e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 81, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.322985643135959e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 82, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.89180186244963e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 83, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.481449324901408e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 84, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.092332998903412e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 85, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.7248368952908065e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 86, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.379323688349517e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 87, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.056134357900478e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 88, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.755587852793717e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 89, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.4779807761443642e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 90, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.223587092621162e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 91, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.926578580764263e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 92, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.85420971784226e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 93, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.02080951531317e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 94, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.42818731782782e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 95, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.0779148512155855e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 96, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.971324671380559e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 97, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.1095088492300012e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 98, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.933178929321103e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 99, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.233599085671e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 100, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 101, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.233599085671e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 102, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.933178929321102e-07
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 103, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.1095088492300007e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 104, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.9713246713805307e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 105, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.077914851215557e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 106, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.4281873178278475e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 107, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.020809515313142e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 108, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.854209717842205e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 109, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.926578580764207e-06
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 110, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.223587092621159e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 111, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.4779807761443637e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 112, Average Loss: nan, Trn Accuracy: 1.00%, lr: 1.7555878527937136e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 113, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.0561343579004686e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 114, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.3793236883495076e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 115, Average Loss: nan, Trn Accuracy: 1.00%, lr: 2.724836895290808e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 116, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.0923329989034126e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 117, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.4814493249014084e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 118, Average Loss: nan, Trn Accuracy: 1.00%, lr: 3.89180186244962e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 119, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.322985643135948e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 120, Average Loss: nan, Trn Accuracy: 1.00%, lr: 4.774575140626305e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 121, Average Loss: nan, Trn Accuracy: 1.00%, lr: 5.2461246906077416e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 122, Average Loss: nan, Trn Accuracy: 1.00%, lr: 5.7371689306052684e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 123, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.247223259238507e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 124, Average Loss: nan, Trn Accuracy: 1.00%, lr: 6.775784314464706e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 125, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.322330470336302e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 126, Average Loss: nan, Trn Accuracy: 1.00%, lr: 7.886322351782783e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 127, Average Loss: nan, Trn Accuracy: 1.00%, lr: 8.4672033669087e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 128, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.06440025628276e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 129, Average Loss: nan, Trn Accuracy: 1.00%, lr: 9.677323658675587e-05
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 130, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00010305368692688169
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 131, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00010947915553696727
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 132, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00011604330125525093
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 133, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00012273964606240723
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 134, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0001295615814745712
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 135, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00013650237506511326
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 136, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00014355517710873194
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 137, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0001507130273413049
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 138, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00015796886182883053
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 139, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00016531551993867713
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 140, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00017274575140626308
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 141, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0001802522234901926
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 142, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00018782752820878642
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 143, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00019546418965086441
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 144, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00020315467135356886
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 145, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00021089138373994227
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 146, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00021866669160892387
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 147, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0002264729216703715
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 148, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00023430237011767168
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 149, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00024214731023046793
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 150, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00024999999999999995
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 151, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00025785268976953195
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 152, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00026569762988232817
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 153, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0002735270783296286
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 154, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00028133330839107606
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 155, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0002891086162600577
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 156, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0002968453286464311
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 157, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00030453581034913554
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 158, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00031217247179121373
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 159, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0003197477765098073
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 160, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0003272542485937368
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 161, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00033468448006132275
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 162, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00034203113817116935
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 163, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.000349286972658695
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 164, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00035644482289126796
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 165, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00036349762493488645
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 166, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00037043841852542895
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 167, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00037726035393759297
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 168, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0003839566987447493
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 169, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00039052084446303275
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 170, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00039694631307311834
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 171, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00040322676341324415
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 172, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00040935599743717243
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 173, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00041532796633091297
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 174, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00042113677648217203
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 175, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00042677669529663675
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 176, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004322421568553529
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 177, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.000437527767407615
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 178, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004426283106939475
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 179, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004475387530939227
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 180, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004522542485937371
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 181, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00045677014356864065
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 182, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.000461081981375504
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 183, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00046518550675098613
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 184, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004690766700109661
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 185, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004727516310470923
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 186, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004762067631165052
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 187, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00047943865642099574
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 188, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004824441214720632
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 189, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.00048522019223855674
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 190, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004877641290737888
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 191, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004900734214192361
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 192, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004921457902821582
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 193, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004939791904846872
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 194, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004955718126821726
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 195, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004969220851487848
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 196, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004980286753286198
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 197, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004988904911507704
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 198, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004995066821070683
Average Val Loss: nan, Val_accuracy: 1.0
Epoch: 199, Average Loss: nan, Trn Accuracy: 1.00%, lr: 0.0004998766400914333
Average Val Loss: nan, Val_accuracy: 1.0
Accuracy on the 10000 test images: 1.0%
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.013 MB uploadedwandb: | 0.013 MB of 0.047 MB uploadedwandb: / 0.047 MB of 0.047 MB uploadedwandb: - 0.047 MB of 0.047 MB uploadedwandb: 
wandb: Run history:
wandb:     average_loss ‚ñà‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ                        
wandb: average_val_loss ‚ñà‚ñá‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ                        
wandb:            epoch ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà
wandb:               lr ‚ñà‚ñà‚ñà‚ñà‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà
wandb:    test_accuracy ‚ñÅ
wandb:     trn_accuracy ‚ñÑ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb:     val_accuracy ‚ñÑ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ
wandb: 
wandb: Run summary:
wandb:     average_loss nan
wandb: average_val_loss nan
wandb:            epoch 199
wandb:               lr 0.0005
wandb:    test_accuracy 1.0
wandb:     trn_accuracy 1.0
wandb:     val_accuracy 1.0
wandb: 
wandb: üöÄ View run trim-vortex-30 at: https://wandb.ai/BDIC-DMML-2024/clip-linear-probe-classification/runs/dwk0ppbj
wandb: ‚≠êÔ∏è View project at: https://wandb.ai/BDIC-DMML-2024/clip-linear-probe-classification
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20240413_202115-dwk0ppbj/logs
